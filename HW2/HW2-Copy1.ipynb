{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import *\n",
    "from keras.layers import Embedding,Bidirectional\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Conv1D,MaxPooling1D,Flatten,GlobalAveragePooling1D\n",
    "from keras.layers import SpatialDropout1D,LSTM,BatchNormalization,Dropout\n",
    "from keras.layers import merge,concatenate\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.initializers import Constant\n",
    "import keras.backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine.topology import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "from collections import  Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop=set(stopwords.words('english'))\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/corrine1106/.conda/envs/py3.7/lib/python3.7/site-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.0) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.2). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "doc = nlp(\"This is a sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for plural nuons\n",
    "import inflect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On average a review has about: 20.413235294117648 words in them\n"
     ]
    }
   ],
   "source": [
    "totalheadline = list(train['Headline'])\n",
    "length = []\n",
    "for i in range(0,len(totalheadline)):\n",
    "        totalheadline[i] = str(totalheadline[i])\n",
    "        a = len(totalheadline[i].split(' '))\n",
    "        length.append(a)\n",
    "\n",
    "    \n",
    "print(\"On average a review has about:\", sum(length)/len(length),\"words in them\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_list = []\n",
    "for label in train.Label.unique():\n",
    "    df_label_list.append(train[train['Label'] == label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Category</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Golden, gaudy and glorious: Dubai has the worl...</td>\n",
       "      <td>travel</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Luis Suarez's bite has ensured his legacy as a...</td>\n",
       "      <td>sport</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Don't leave her hanging! radio Dj gets stuck o...</td>\n",
       "      <td>travel</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>'If people get snotty about me, i just think g...</td>\n",
       "      <td>gardening</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Would you go vegan for Beyonce? singer launche...</td>\n",
       "      <td>food</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>2013</td>\n",
       "      <td>What's your taser face? photo Series captures ...</td>\n",
       "      <td>femail</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>2017</td>\n",
       "      <td>Bride and groom who spent four years planning ...</td>\n",
       "      <td>health</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>2022</td>\n",
       "      <td>From anorexia to bodybuilding champion: woman,...</td>\n",
       "      <td>health</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>2027</td>\n",
       "      <td>Now that's fast food! inside the roller-coaste...</td>\n",
       "      <td>food</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>2030</td>\n",
       "      <td>Why is the milky way blowing bubbles? portrait...</td>\n",
       "      <td>sciencetech</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                           Headline     Category  \\\n",
       "0        1  Golden, gaudy and glorious: Dubai has the worl...       travel   \n",
       "4        5  Luis Suarez's bite has ensured his legacy as a...        sport   \n",
       "6        7  Don't leave her hanging! radio Dj gets stuck o...       travel   \n",
       "7        8  'If people get snotty about me, i just think g...    gardening   \n",
       "14      15  Would you go vegan for Beyonce? singer launche...         food   \n",
       "...    ...                                                ...          ...   \n",
       "2012  2013  What's your taser face? photo Series captures ...       femail   \n",
       "2016  2017  Bride and groom who spent four years planning ...       health   \n",
       "2021  2022  From anorexia to bodybuilding champion: woman,...       health   \n",
       "2026  2027  Now that's fast food! inside the roller-coaste...         food   \n",
       "2029  2030  Why is the milky way blowing bubbles? portrait...  sciencetech   \n",
       "\n",
       "      Label  \n",
       "0       4.0  \n",
       "4       4.0  \n",
       "6       4.0  \n",
       "7       4.0  \n",
       "14      4.0  \n",
       "...     ...  \n",
       "2012    4.0  \n",
       "2016    4.0  \n",
       "2021    4.0  \n",
       "2026    4.0  \n",
       "2029    4.0  \n",
       "\n",
       "[226 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpus(df,column):\n",
    "    corpus=[]\n",
    "    \n",
    "    for x in df[column].str.split():\n",
    "        for i in x:\n",
    "            corpus.append(i)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.]\n",
      "sciencetech    51\n",
      "health         40\n",
      "food           37\n",
      "femail         31\n",
      "news           25\n",
      "travel         24\n",
      "books           6\n",
      "travelnews      5\n",
      "football        2\n",
      "home            2\n",
      "sport           2\n",
      "gardening       1\n",
      "Name: Category, dtype: int64\n",
      "[2.33333333]\n",
      "football       50\n",
      "news           36\n",
      "femail         28\n",
      "travel         21\n",
      "health         19\n",
      "sciencetech    15\n",
      "food           10\n",
      "books           3\n",
      "gardening       3\n",
      "rugbyunion      2\n",
      "sport           2\n",
      "othersports     1\n",
      "racing          1\n",
      "cricket         1\n",
      "boxing          1\n",
      "tennis          1\n",
      "Name: Category, dtype: int64\n",
      "[4.5]\n",
      "news           9\n",
      "health         8\n",
      "travel         8\n",
      "sciencetech    7\n",
      "food           5\n",
      "femail         3\n",
      "books          2\n",
      "football       1\n",
      "Name: Category, dtype: int64\n",
      "[3.33333333]\n",
      "travel         55\n",
      "femail         54\n",
      "sciencetech    51\n",
      "health         50\n",
      "news           45\n",
      "food           33\n",
      "football       13\n",
      "books           8\n",
      "travelnews      2\n",
      "sport           2\n",
      "Name: Category, dtype: int64\n",
      "[3.66666667]\n",
      "sciencetech    53\n",
      "health         43\n",
      "travel         41\n",
      "femail         40\n",
      "food           35\n",
      "news           28\n",
      "books          14\n",
      "football        2\n",
      "othersports     1\n",
      "tennis          1\n",
      "home            1\n",
      "gardening       1\n",
      "Name: Category, dtype: int64\n",
      "[2.66666667]\n",
      "football       54\n",
      "femail         44\n",
      "news           41\n",
      "health         32\n",
      "sciencetech    31\n",
      "travel         31\n",
      "food           21\n",
      "rugbyunion      4\n",
      "othersports     4\n",
      "tennis          4\n",
      "formulaone      3\n",
      "cricket         3\n",
      "books           2\n",
      "boxing          1\n",
      "home            1\n",
      "golf            1\n",
      "sport           1\n",
      "gardening       1\n",
      "racing          1\n",
      "concussion      1\n",
      "Name: Category, dtype: int64\n",
      "[2.]\n",
      "football       43\n",
      "femail         19\n",
      "health         16\n",
      "travel         14\n",
      "news           13\n",
      "books           7\n",
      "food            3\n",
      "sciencetech     3\n",
      "othersports     3\n",
      "tennis          3\n",
      "rugbyunion      3\n",
      "sport           2\n",
      "gardening       2\n",
      "home            1\n",
      "golf            1\n",
      "cricket         1\n",
      "boxing          1\n",
      "Name: Category, dtype: int64\n",
      "[2.5]\n",
      "health         7\n",
      "sciencetech    7\n",
      "travel         6\n",
      "food           4\n",
      "femail         4\n",
      "news           4\n",
      "football       2\n",
      "books          1\n",
      "othersports    1\n",
      "Name: Category, dtype: int64\n",
      "[1.66666667]\n",
      "football       7\n",
      "rugbyunion     3\n",
      "news           3\n",
      "travel         3\n",
      "books          2\n",
      "cricket        2\n",
      "tennis         2\n",
      "sciencetech    2\n",
      "food           1\n",
      "othersports    1\n",
      "health         1\n",
      "golf           1\n",
      "Name: Category, dtype: int64\n",
      "[3.]\n",
      "news           69\n",
      "travel         57\n",
      "health         50\n",
      "femail         44\n",
      "sciencetech    40\n",
      "football       37\n",
      "food           36\n",
      "books           8\n",
      "golf            2\n",
      "gardening       2\n",
      "tennis          2\n",
      "home            2\n",
      "rugbyunion      1\n",
      "boxing          1\n",
      "formulaone      1\n",
      "beauty          1\n",
      "sport           1\n",
      "Name: Category, dtype: int64\n",
      "[4.33333333]\n",
      "sciencetech    23\n",
      "femail         12\n",
      "news           11\n",
      "food           10\n",
      "travel         10\n",
      "health          8\n",
      "books           6\n",
      "travelnews      1\n",
      "football        1\n",
      "Name: Category, dtype: int64\n",
      "[4.66666667]\n",
      "health         8\n",
      "sciencetech    5\n",
      "femail         4\n",
      "food           3\n",
      "books          3\n",
      "travel         3\n",
      "news           2\n",
      "travelnews     1\n",
      "Name: Category, dtype: int64\n",
      "[1.5]\n",
      "travel         5\n",
      "femail         4\n",
      "health         3\n",
      "books          1\n",
      "othersports    1\n",
      "football       1\n",
      "news           1\n",
      "Name: Category, dtype: int64\n",
      "[3.5]\n",
      "food           7\n",
      "football       4\n",
      "sciencetech    3\n",
      "books          2\n",
      "travel         2\n",
      "femail         2\n",
      "news           2\n",
      "Name: Category, dtype: int64\n",
      "[1.33333333]\n",
      "football      2\n",
      "food          1\n",
      "rugbyunion    1\n",
      "Name: Category, dtype: int64\n",
      "[1.]\n",
      "football    1\n",
      "sport       1\n",
      "health      1\n",
      "travel      1\n",
      "femail      1\n",
      "Name: Category, dtype: int64\n",
      "[5.]\n",
      "health         3\n",
      "food           2\n",
      "travel         2\n",
      "news           2\n",
      "books          1\n",
      "femail         1\n",
      "sciencetech    1\n",
      "Name: Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for df in df_label_list:\n",
    "    print(df.Label.unique())\n",
    "    print(df.Category.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stop = stop-set(['what',\n",
    " 'when',\n",
    " 'where',\n",
    " 'which',\n",
    " 'while',\n",
    " 'whom',\n",
    " 'over'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = create_corpus(train,'Headline')\n",
    "dic=defaultdict(int)\n",
    "for word in corpus:\n",
    "    if word in new_stop:\n",
    "        dic[word]+=1\n",
    "        \n",
    "top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train,test])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Golden, gaudy and glorious: Dubai has the world's tallest building and biggest airport... is it about to overtake London as the most visited city?\""
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Headline[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport = ['sport', 'football',  'golf', 'rugbyunion', 'boxing', 'tennis','othersports']\n",
    "non_sport = ['travel', 'health', 'femail', 'gardening', 'sciencetech',\n",
    "       'news', 'food',  'travelnews', 'cricket', \n",
    "       'books', 'home', 'concussion','beauty', 'formulaone', 'racing', 'living',\n",
    "       'middleeast', 'us']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sport = pd.DataFrame([])\n",
    "for i in sport:\n",
    "    df_sport = df_sport.append(df[df['Category'] == i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_sport = pd.DataFrame([])\n",
    "for i in non_sport:\n",
    "    df_non_sport = df_non_sport.append(df[df['Category'] == i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean puctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_sport['Headline']=df_non_sport['Headline'].apply(lambda x : x.replace(\"'s\",' '))\n",
    "df_non_sport['Headline']=df_non_sport['Headline'].apply(lambda x : x.replace(\"s'\",' '))\n",
    "df_sport['Headline']=df_sport['Headline'].apply(lambda x : x.replace(\"'s\",' '))\n",
    "df_sport['Headline']=df_sport['Headline'].apply(lambda x : x.replace(\"s'\",' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Category</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Luis Suarez  bite has ensured his legacy as a ...</td>\n",
       "      <td>sport</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>Premier League top 10 debuts: Diego Costa, Ces...</td>\n",
       "      <td>sport</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>220</td>\n",
       "      <td>Yoann Huget warned by The European Professiona...</td>\n",
       "      <td>sport</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>315</td>\n",
       "      <td>Dani Alves reaches 300 appearances for Barcelo...</td>\n",
       "      <td>sport</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>339</td>\n",
       "      <td>Andre-Pierre Gignac  transfer from Toulouse to...</td>\n",
       "      <td>sport</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                           Headline Category     Label\n",
       "4      5  Luis Suarez  bite has ensured his legacy as a ...    sport  4.000000\n",
       "59    60  Premier League top 10 debuts: Diego Costa, Ces...    sport  3.000000\n",
       "219  220  Yoann Huget warned by The European Professiona...    sport  2.000000\n",
       "314  315  Dani Alves reaches 300 appearances for Barcelo...    sport  2.000000\n",
       "338  339  Andre-Pierre Gignac  transfer from Toulouse to...    sport  2.333333"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sport.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = '\"#$%&\\'()*+,./:;<=>@[\\\\]^_`{|}~!?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    table=str.maketrans('','',punctuation)\n",
    "    return text.translate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry i spent it on myself Harvey Nichols hilarious Christmas advert sees people treating themselves instead of others\n"
     ]
    }
   ],
   "source": [
    "example=\"Sorry, i spent it on myself! Harvey Nichol's hilarious Christmas advert sees people treating themselves instead of others\"\n",
    "print(remove_punct(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### football club"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "football_club_list = ['Alavés','Athletic Bilbao','Atlético Madrid','Barcelona'\n",
    "                      ,'Cádiz','Celta Vigo','Eibar','Elche','Getafe','Granada'\n",
    "                     ,'Huesca','Levante','Osasuna','Real Betis','Real Madrid','Real Sociedad','Sevilla'\n",
    "                     ,'Valencia','Valladolid','Villarreal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def football_club(title):\n",
    "    word_list = title.split(' ')\n",
    "    for word in word_list:\n",
    "        if word in football_club_list:\n",
    "            title = title.replace(word,'football club')\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sport['Headline']=df_sport['Headline'].apply(lambda x : football_club(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "footballer_list = ['Paul Pogba','Dejan Lovren']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def footballer(title):\n",
    "    word_list = title.split(' ')\n",
    "    for word in word_list:\n",
    "        if word in footballer_list:\n",
    "            title = title.replace(word,'footballer')\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sport['Headline']=df_sport['Headline'].apply(lambda x : footballer(x))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "p = inflect.engine()\n",
    "print(p.plural('cat'),p.singular_noun('glorious'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def trans_plural(title):\n",
    "    for word in title.split(' '):\n",
    "        if p.singular_noun(word) != False and p.singular_noun(word) != word:\n",
    "            title = title.replace(word, p.singular_noun(word))\n",
    "    return title"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_non_sport['Headline']=df_non_sport['Headline'].apply(lambda x : trans_plural(x))\n",
    "df_sport['Headline']=df_sport['Headline'].apply(lambda x : trans_plural(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['£ 180', '£ 5']"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"£ \\d*\\,?\\d+\\.?\\d*\",df.Headline[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_money(title):\n",
    "    money_list = re.findall(r\"£ \\d*\\,?\\d+\\.?\\d*\",title)\n",
    "    if not money_list:\n",
    "        return title\n",
    "    else:\n",
    "        for money in money_list:\n",
    "            title = title.replace(money, 'money')\n",
    "        return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_name(title):\n",
    "    doc = nlp(title)\n",
    "    if not doc.ents :\n",
    "        return title\n",
    "    else:\n",
    "        for X in doc.ents:\n",
    "            if X.label_=='PERSON':\n",
    "                title = title.replace(X.text, ' ')\n",
    "                \n",
    "    return title\n",
    "            \n",
    "def remove_date(title):\n",
    "    doc = nlp(title)\n",
    "    if not doc.ents :\n",
    "        return title\n",
    "    else:\n",
    "        for X in doc.ents:\n",
    "            if X.label_=='DATE':\n",
    "                title = title.replace(X.text, ' ')\n",
    "                \n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_name(title):\n",
    "    doc = nlp(title)\n",
    "    if not doc.ents :\n",
    "        return title\n",
    "    else:\n",
    "        for X in doc.ents:\n",
    "            if X.label_=='PERSON':\n",
    "                print(title)\n",
    "                title = title.replace(X.text, 'athlete')\n",
    "        return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sport['Headline']=df_sport['Headline'].apply(lambda x : remove_name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_sport.append(df_non_sport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sport', 'football', 'golf', 'rugbyunion', 'boxing', 'tennis',\n",
       "       'othersports', 'travel', 'health', 'femail', 'gardening',\n",
       "       'sciencetech', 'news', 'food', 'travelnews', 'cricket', 'books',\n",
       "       'home', 'concussion', 'beauty', 'formulaone', 'racing', 'living',\n",
       "       'middleeast', 'us'], dtype=object)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Headline']=df['Headline'].apply(lambda x : remove_date(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Headline']=df['Headline'].apply(lambda x : replace_money(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Headline']=df['Headline'].apply(lambda x : remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Golden gaudy and glorious Dubai has the world  tallest building and biggest airport is it about to overtake London as the most visited city'"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Headline[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_stop = set([\"would\",'could','new','hi','say','world','reveal','money','first','one','reveals','says','over'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']=df['Headline'].apply(lambda x : remove_punct(x))\n",
    "df['tokenized'] = df['Headline'].apply(word_tokenize)\n",
    "\n",
    "\n",
    "\n",
    "df['lower'] = df['tokenized'].apply(lambda x: [word.lower() for word in x])\n",
    "\n",
    "df['no_stopwords'] = df['lower'].apply(lambda x: [word for word in x if word not in new_stop]) #if word not in new_stop\n",
    "df['no_stopwords'] = df['no_stopwords'].apply(lambda x: [word for word in x if word not in other_stop])\n",
    "df['no_stopwords'] = [' '.join(map(str, l)) for l in df['no_stopwords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['no_stopwords'] = df['no_stopwords'].apply(lambda x: x.replace(\"!\", \"?\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df['no_stopwords'] = df['no_stopwords'].apply(lambda x: x.replace(\"would\", ''))\n",
    "df['no_stopwords'] = df['no_stopwords'].apply(lambda x: x.replace(\"could\", ''))\n",
    "df['no_stopwords'] = df['no_stopwords'].apply(lambda x: x.replace(\"new\", ''))\n",
    "df['no_stopwords'] = df['no_stopwords'].apply(lambda x: x.replace(\"hi\", ''))\n",
    "df['no_stopwords'] = df['no_stopwords'].apply(lambda x: x.replace(\"say\", ''))\n",
    "df['no_stopwords'] = df['no_stopwords'].apply(lambda x: x.replace(\"world\", ''))\n",
    "df['no_stopwords'] = df['no_stopwords'].apply(lambda x: x.replace(\"reveal\", ''))\n",
    "#df['no_stopwords'] = df['no_stopwords'].apply(lambda x: x.replace(\"wa\", ''))\n",
    "df['no_stopwords'] = df['no_stopwords'].apply(lambda x: x.replace(\"s\", ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['no_stopwords'] = df['no_stopwords'].apply(lambda x: x.replace(\"polouse\", 'scenery'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_list = []\n",
    "for label in df.Label.unique():\n",
    "    if np.isnan(label) == False:\n",
    "        df_label_list.append(df[df['Label'] == label])\n",
    "label_top = defaultdict(list)\n",
    "for df_label in df_label_list:\n",
    "    corpus = create_corpus(df_label,'no_stopwords')\n",
    "    dic=defaultdict(int)\n",
    "    for word in corpus:\n",
    "        dic[word]+=1\n",
    "        \n",
    "    top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] \n",
    "    label_top[df_label.Label.unique()[0]] = top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = create_corpus(df,'no_stopwords')\n",
    "dic=defaultdict(int)\n",
    "for word in corpus:\n",
    "    dic[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counter=Counter(corpus)\n",
    "most=counter.most_common()\n",
    "\n",
    "x, y= [], []\n",
    "for word,count in most[:30]:\n",
    "    x.append(word)\n",
    "    y.append(count)\n",
    "sns.barplot(x=y,y=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('get', 58),\n",
       " ('life', 57),\n",
       " ('woman', 57),\n",
       " ('best', 57),\n",
       " ('people', 56),\n",
       " ('man', 55),\n",
       " ('star', 54),\n",
       " ('time', 53),\n",
       " ('back', 53),\n",
       " ('cancer', 51),\n",
       " ('women', 51),\n",
       " ('what', 51),\n",
       " ('london', 50),\n",
       " ('city', 49),\n",
       " ('like', 49),\n",
       " ('when', 49),\n",
       " ('make', 47),\n",
       " ('love', 47),\n",
       " ('mother', 46),\n",
       " ('claims', 46),\n",
       " ('united', 45),\n",
       " ('made', 44),\n",
       " ('dont', 44),\n",
       " ('even', 44),\n",
       " ('manchester', 43),\n",
       " ('food', 43),\n",
       " ('revealed', 40),\n",
       " ('home', 40),\n",
       " ('family', 40),\n",
       " ('league', 39),\n",
       " ('top', 39),\n",
       " ('day', 39),\n",
       " ('two', 38),\n",
       " ('hotel', 38),\n",
       " ('three', 38),\n",
       " ('uk', 37),\n",
       " ('help', 37),\n",
       " ('dinner', 37),\n",
       " ('children', 37),\n",
       " ('british', 36),\n",
       " ('eat', 36),\n",
       " ('us', 36),\n",
       " ('real', 36),\n",
       " ('baby', 36),\n",
       " ('scientists', 36),\n",
       " ('set', 36),\n",
       " ('restaurant', 36),\n",
       " ('go', 35),\n",
       " ('england', 35),\n",
       " ('where', 35),\n",
       " ('may', 34),\n",
       " ('red', 34),\n",
       " ('police', 34),\n",
       " ('left', 33),\n",
       " ('found', 33),\n",
       " ('cup', 33),\n",
       " ('arsenal', 33),\n",
       " ('inside', 33),\n",
       " ('holiday', 33),\n",
       " ('britain', 33),\n",
       " ('take', 32),\n",
       " ('still', 32),\n",
       " ('death', 32),\n",
       " ('face', 31),\n",
       " ('men', 31),\n",
       " ('cant', 31),\n",
       " ('way', 31),\n",
       " ('video', 30),\n",
       " ('girl', 30),\n",
       " ('tv', 30),\n",
       " ('while', 30),\n",
       " ('football', 30),\n",
       " ('sex', 30),\n",
       " ('study', 29),\n",
       " ('goes', 29),\n",
       " ('good', 29),\n",
       " ('risk', 29),\n",
       " ('ever', 28),\n",
       " ('want', 28),\n",
       " ('doctors', 28),\n",
       " ('creates', 27),\n",
       " ('pay', 27),\n",
       " ('stars', 27),\n",
       " ('really', 27),\n",
       " ('10', 26),\n",
       " ('apple', 26),\n",
       " ('look', 26),\n",
       " ('car', 26),\n",
       " ('club', 26),\n",
       " ('using', 25),\n",
       " ('luxury', 25),\n",
       " ('forget', 25),\n",
       " ('fashion', 25),\n",
       " ('water', 25),\n",
       " ('ice', 25),\n",
       " ('heart', 25),\n",
       " ('away', 24),\n",
       " ('play', 24),\n",
       " ('disease', 24),\n",
       " ('fans', 24),\n",
       " ('wine', 24),\n",
       " ('live', 24),\n",
       " ('save', 24),\n",
       " ('half', 23),\n",
       " ('premier', 23),\n",
       " ('never', 23),\n",
       " ('chelsea', 23),\n",
       " ('secret', 23),\n",
       " ('health', 23),\n",
       " ('brain', 23),\n",
       " ('earth', 23),\n",
       " ('give', 22),\n",
       " ('meet', 22),\n",
       " ('boss', 22),\n",
       " ('stop', 22),\n",
       " ('--', 22),\n",
       " ('every', 22),\n",
       " ('shows', 22),\n",
       " ('surgery', 22),\n",
       " ('end', 22),\n",
       " ('times', 22),\n",
       " ('great', 22),\n",
       " ('four', 22),\n",
       " ('wife', 21),\n",
       " ('team', 21),\n",
       " ('prince', 21),\n",
       " ('son', 21),\n",
       " ('ahead', 21),\n",
       " ('air', 21),\n",
       " ('charity', 21),\n",
       " ('big', 21),\n",
       " ('hit', 21),\n",
       " ('show', 21),\n",
       " ('gives', 21),\n",
       " ('takes', 21),\n",
       " ('york', 21),\n",
       " ('which', 20),\n",
       " ('madrid', 20),\n",
       " ('little', 20),\n",
       " ('stunning', 20),\n",
       " ('find', 20),\n",
       " ('daughter', 20),\n",
       " ('favourite', 20),\n",
       " ('told', 20),\n",
       " ('run', 20),\n",
       " ('use', 20),\n",
       " ('sale', 20),\n",
       " ('put', 19),\n",
       " ('condition', 19),\n",
       " ('tea', 19),\n",
       " ('win', 19),\n",
       " ('celebrity', 19),\n",
       " ('island', 19),\n",
       " ('sign', 19),\n",
       " ('husband', 19),\n",
       " ('dead', 19),\n",
       " ('including', 19),\n",
       " ('expensive', 19),\n",
       " ('boy', 19),\n",
       " ('body', 19),\n",
       " ('america', 18),\n",
       " ('drug', 18),\n",
       " ('launches', 18),\n",
       " ('hot', 18),\n",
       " ('skin', 18),\n",
       " ('attack', 18),\n",
       " ('future', 18),\n",
       " ('online', 18),\n",
       " ('patients', 18),\n",
       " ('year', 18),\n",
       " ('images', 18),\n",
       " ('eating', 18),\n",
       " ('makes', 18),\n",
       " ('former', 18),\n",
       " ('hospital', 18),\n",
       " ('killed', 18),\n",
       " ('return', 18),\n",
       " ('likely', 18),\n",
       " ('house', 18),\n",
       " ('pregnant', 18),\n",
       " ('chance', 18),\n",
       " ('million', 17),\n",
       " ('gets', 17),\n",
       " ('west', 17),\n",
       " ('better', 17),\n",
       " ('looks', 17),\n",
       " ('google', 17),\n",
       " ('sea', 17),\n",
       " ('book', 17),\n",
       " ('need', 17),\n",
       " ('gold', 17),\n",
       " ('head', 17),\n",
       " ('finally', 17),\n",
       " ('kate', 17),\n",
       " ('parents', 17),\n",
       " ('school', 17),\n",
       " ('queen', 17),\n",
       " ('internet', 16),\n",
       " ('liverpool', 16),\n",
       " ('moment', 16),\n",
       " ('couple', 16),\n",
       " ('planet', 16),\n",
       " ('service', 16),\n",
       " ('travel', 16),\n",
       " ('hair', 16),\n",
       " ('beauty', 16),\n",
       " ('model', 16),\n",
       " ('calls', 16),\n",
       " ('high', 16),\n",
       " ('without', 16),\n",
       " ('young', 16),\n",
       " ('lost', 16),\n",
       " ('size', 16),\n",
       " ('chocolate', 16),\n",
       " ('around', 16),\n",
       " ('facebook', 16),\n",
       " ('phone', 16),\n",
       " ('game', 16),\n",
       " ('despite', 16),\n",
       " ('birth', 16),\n",
       " ('style', 16),\n",
       " ('become', 15),\n",
       " ('match', 15),\n",
       " ('light', 15),\n",
       " ('experts', 15),\n",
       " ('due', 15),\n",
       " ('old', 15),\n",
       " ('taking', 15),\n",
       " ('blood', 15),\n",
       " ('champions', 15),\n",
       " ('wedding', 15),\n",
       " ('eye', 15),\n",
       " ('side', 15),\n",
       " ('much', 15),\n",
       " ('space', 15),\n",
       " ('child', 15),\n",
       " ('cake', 15),\n",
       " ('bid', 15),\n",
       " ('turkey', 15),\n",
       " ('power', 15),\n",
       " ('right', 15),\n",
       " ('fish', 15),\n",
       " ('come', 15),\n",
       " ('see', 15),\n",
       " ('unveils', 15),\n",
       " ('clash', 15),\n",
       " ('mystery', 15),\n",
       " ('burger', 15),\n",
       " ('weight', 15),\n",
       " ('used', 15),\n",
       " ('french', 15),\n",
       " ('six', 15),\n",
       " ('30', 15),\n",
       " ('many', 15),\n",
       " ('night', 15),\n",
       " ('drink', 14),\n",
       " ('worst', 14),\n",
       " ('almost', 14),\n",
       " ('20', 14),\n",
       " ('virus', 14),\n",
       " ('giant', 14),\n",
       " ('rare', 14),\n",
       " ('perfect', 14),\n",
       " ('forced', 14),\n",
       " ('royal', 14),\n",
       " ('chef', 14),\n",
       " ('human', 14),\n",
       " ('war', 14),\n",
       " ('battle', 14),\n",
       " ('long', 14),\n",
       " ('watch', 14),\n",
       " ('south', 14),\n",
       " ('doesnt', 14),\n",
       " ('meals', 14),\n",
       " ('father', 14),\n",
       " ('claim', 14),\n",
       " ('create', 14),\n",
       " ('student', 14),\n",
       " ('opens', 14),\n",
       " ('double', 14),\n",
       " ('nhs', 14),\n",
       " ('kim', 14),\n",
       " ('open', 14),\n",
       " ('walk', 14),\n",
       " ('making', 14),\n",
       " ('going', 14),\n",
       " ('ancient', 14),\n",
       " ('know', 14),\n",
       " ('wont', 14),\n",
       " ('behind', 14),\n",
       " ('got', 14),\n",
       " ('change', 14),\n",
       " ('think', 13),\n",
       " ('move', 13),\n",
       " ('full', 13),\n",
       " ('view', 13),\n",
       " ('female', 13),\n",
       " ('record', 13),\n",
       " ('twice', 13),\n",
       " ('call', 13),\n",
       " ('history', 13),\n",
       " ('since', 13),\n",
       " ('europe', 13),\n",
       " ('treatment', 13),\n",
       " ('striker', 13),\n",
       " ('fat', 13),\n",
       " ('guide', 13),\n",
       " ('campaign', 13),\n",
       " ('50', 13),\n",
       " ('helps', 13),\n",
       " ('girls', 13),\n",
       " ('cut', 13),\n",
       " ('technology', 13),\n",
       " ('front', 13),\n",
       " ('injury', 13),\n",
       " ('visit', 13),\n",
       " ('keep', 13),\n",
       " ('comes', 13),\n",
       " ('nothing', 13),\n",
       " ('price', 13),\n",
       " ('beach', 13),\n",
       " ('five', 13),\n",
       " ('finds', 13),\n",
       " ('glorious', 12),\n",
       " ('3d', 12),\n",
       " ('britons', 12),\n",
       " ('happy', 12),\n",
       " ('hours', 12),\n",
       " ('capital', 12),\n",
       " ('far', 12),\n",
       " ('complete', 12),\n",
       " ('thought', 12),\n",
       " ('calories', 12),\n",
       " ('american', 12),\n",
       " ('stone', 12),\n",
       " ('iphone', 12),\n",
       " ('views', 12),\n",
       " ('amazing', 12),\n",
       " ('build', 12),\n",
       " ('plans', 12),\n",
       " ('admits', 12),\n",
       " ('let', 12),\n",
       " ('app', 12),\n",
       " ('cream', 12),\n",
       " ('spain', 12),\n",
       " ('inspector', 12),\n",
       " ('getting', 12),\n",
       " ('kardashian', 12),\n",
       " ('deal', 12),\n",
       " ('work', 12),\n",
       " ('lose', 12),\n",
       " ('newcastle', 12),\n",
       " ('flying', 12),\n",
       " ('bizarre', 12),\n",
       " ('milk', 12),\n",
       " ('photos', 12),\n",
       " ('week', 12),\n",
       " ('hand', 12),\n",
       " ('crowned', 12),\n",
       " ('park', 12),\n",
       " ('enough', 12),\n",
       " ('beer', 12),\n",
       " ('suffer', 12),\n",
       " ('nasa', 12),\n",
       " ('black', 12),\n",
       " ('golden', 11),\n",
       " ('biggest', 11),\n",
       " ('airport', 11),\n",
       " ('tourists', 11),\n",
       " ('break', 11),\n",
       " ('final', 11),\n",
       " ('sun', 11),\n",
       " ('fine', 11),\n",
       " ('greatest', 11),\n",
       " ('party', 11),\n",
       " ('firm', 11),\n",
       " ('became', 11),\n",
       " ('among', 11),\n",
       " ('6', 11),\n",
       " ('tour', 11),\n",
       " ('cook', 11),\n",
       " ('round', 11),\n",
       " ('boost', 11),\n",
       " ('warning', 11),\n",
       " ('hits', 11),\n",
       " ('caribbean', 11),\n",
       " ('range', 11),\n",
       " ('middle', 11),\n",
       " ('latest', 11),\n",
       " ('system', 11),\n",
       " ('officer', 11),\n",
       " ('ebola', 11),\n",
       " ('100', 11),\n",
       " ('street', 11),\n",
       " ('robot', 11),\n",
       " ('across', 11),\n",
       " ('breakfast', 11),\n",
       " ('fast', 11),\n",
       " ('indian', 11),\n",
       " ('incredible', 11),\n",
       " ('warns', 11),\n",
       " ('france', 11),\n",
       " ('wearing', 11),\n",
       " ('obese', 11),\n",
       " ('raise', 11),\n",
       " ('glass', 11),\n",
       " ('seen', 11),\n",
       " ('birthday', 11),\n",
       " ('fancy', 11),\n",
       " ('shot', 11),\n",
       " ('fit', 11),\n",
       " ('festive', 11),\n",
       " ('chinese', 11),\n",
       " ('part', 11),\n",
       " ('leave', 10),\n",
       " ('lives', 10),\n",
       " ('palace', 10),\n",
       " ('breast', 10),\n",
       " ('dramatic', 10),\n",
       " ('ban', 10),\n",
       " ('tottenham', 10),\n",
       " ('bad', 10),\n",
       " ('climate', 10),\n",
       " ('dream', 10),\n",
       " ('mars', 10),\n",
       " ('shop', 10),\n",
       " ('harry', 10),\n",
       " ('buy', 10),\n",
       " ('bill', 10),\n",
       " ('murder', 10),\n",
       " ('living', 10),\n",
       " ('german', 10),\n",
       " ('fruit', 10),\n",
       " ('healthy', 10),\n",
       " ('place', 10),\n",
       " ('discover', 10),\n",
       " ('close', 10),\n",
       " ('moon', 10),\n",
       " ('moving', 10),\n",
       " ('champagne', 10),\n",
       " ('friends', 10),\n",
       " ('news', 10),\n",
       " ('dog', 10),\n",
       " ('chips', 10),\n",
       " ('diet', 10),\n",
       " ('exclusive', 10),\n",
       " ('rules', 10),\n",
       " ('brazil', 10),\n",
       " ('george', 10),\n",
       " ('meal', 10),\n",
       " ('thanks', 10),\n",
       " ('ill', 10),\n",
       " ('plan', 10),\n",
       " ('fight', 10),\n",
       " ('australian', 10),\n",
       " ('following', 10),\n",
       " ('duchess', 10),\n",
       " ('offers', 10),\n",
       " ('inspired', 10),\n",
       " ('treat', 10),\n",
       " ('free', 10),\n",
       " ('william', 10),\n",
       " ('eggs', 10),\n",
       " ('thousands', 10),\n",
       " ('lets', 10),\n",
       " ('teenager', 10),\n",
       " ('looking', 10),\n",
       " ('turned', 10),\n",
       " ('princess', 10),\n",
       " ('another', 10),\n",
       " ('film', 10),\n",
       " ('menu', 10),\n",
       " ('david', 10),\n",
       " ('diagnosed', 10),\n",
       " ('twitter', 10),\n",
       " ('beautiful', 10),\n",
       " ('stay', 10),\n",
       " ('femail', 10),\n",
       " ('test', 10),\n",
       " ('babies', 10),\n",
       " ('becomes', 10),\n",
       " ('rise', 10),\n",
       " ('grand', 10),\n",
       " ('insists', 10),\n",
       " ('lunch', 10),\n",
       " ('killer', 10),\n",
       " ('minutes', 10),\n",
       " ('prevent', 9),\n",
       " ('artist', 9),\n",
       " ('victory', 9),\n",
       " ('die', 9),\n",
       " ('age', 9),\n",
       " ('exercise', 9),\n",
       " ('storm', 9),\n",
       " ('leaves', 9),\n",
       " ('wants', 9),\n",
       " ('bring', 9),\n",
       " ('giving', 9),\n",
       " ('cells', 9),\n",
       " ('believe', 9),\n",
       " ('state', 9),\n",
       " ('list', 9),\n",
       " ('valentine', 9),\n",
       " ('weekend', 9),\n",
       " ('try', 9),\n",
       " ('stuart', 9),\n",
       " ('glamour', 9),\n",
       " ('sky', 9),\n",
       " ('scotland', 9),\n",
       " ('report', 9),\n",
       " ('saved', 9),\n",
       " ('cure', 9),\n",
       " ('ham', 9),\n",
       " ('cost', 9),\n",
       " ('players', 9),\n",
       " ('number', 9),\n",
       " ('wins', 9),\n",
       " ('diners', 9),\n",
       " ('lead', 9),\n",
       " ('frozen', 9),\n",
       " ('suffering', 9),\n",
       " ('well', 9),\n",
       " ('wrong', 9),\n",
       " ('photo', 9),\n",
       " ('africa', 9),\n",
       " ('map', 9),\n",
       " ('energy', 9),\n",
       " ('white', 9),\n",
       " ('international', 9),\n",
       " ('king', 9),\n",
       " ('met', 9),\n",
       " ('journey', 9),\n",
       " ('forward', 9),\n",
       " ('roast', 9),\n",
       " ('music', 9),\n",
       " ('users', 9),\n",
       " ('tax', 9),\n",
       " ('families', 9),\n",
       " ('train', 9),\n",
       " ('paris', 9),\n",
       " ('loses', 9),\n",
       " ('models', 9),\n",
       " ('steps', 9),\n",
       " ('born', 9),\n",
       " ('office', 9),\n",
       " ('sir', 9),\n",
       " ('vs', 9),\n",
       " ('actually', 9),\n",
       " ('feel', 9),\n",
       " ('east', 9),\n",
       " ('passengers', 9),\n",
       " ('turns', 9),\n",
       " ('designer', 9),\n",
       " ('arrested', 9),\n",
       " ('group', 9),\n",
       " ('discovers', 9),\n",
       " ('given', 9),\n",
       " ('spot', 9),\n",
       " ('crash', 9),\n",
       " ('art', 9),\n",
       " ('partner', 8),\n",
       " ('radio', 8),\n",
       " ('name', 8),\n",
       " ('squad', 8),\n",
       " ('expert', 8),\n",
       " ('marriage', 8),\n",
       " ('warn', 8),\n",
       " ('anyone', 8),\n",
       " ('finish', 8),\n",
       " ('developing', 8),\n",
       " ('court', 8),\n",
       " ('nearly', 8),\n",
       " ('morning', 8),\n",
       " ('didnt', 8),\n",
       " ('working', 8),\n",
       " ('search', 8),\n",
       " ('scottish', 8),\n",
       " ('serves', 8),\n",
       " ('per', 8),\n",
       " ('tourist', 8),\n",
       " ('early', 8),\n",
       " ('lady', 8),\n",
       " ('islands', 8),\n",
       " ('shock', 8),\n",
       " ('winner', 8),\n",
       " ('cricket', 8),\n",
       " ('obama', 8),\n",
       " ('race', 8),\n",
       " ('north', 8),\n",
       " ('24', 8),\n",
       " ('third', 8),\n",
       " ('electric', 8),\n",
       " ('mothers', 8),\n",
       " ('brits', 8),\n",
       " ('brussels', 8),\n",
       " ('taken', 8),\n",
       " ('juice', 8),\n",
       " ('sprouts', 8),\n",
       " ('smart', 8),\n",
       " ('lingerie', 8),\n",
       " ('must', 8),\n",
       " ('aged', 8),\n",
       " ('gave', 8),\n",
       " ('beef', 8),\n",
       " ('guests', 8),\n",
       " ('owner', 8),\n",
       " ('catwalk', 8),\n",
       " ('boys', 8),\n",
       " ('obesity', 8),\n",
       " ('doctor', 8),\n",
       " ('tests', 8),\n",
       " ('blame', 8),\n",
       " ('speed', 8),\n",
       " ('camera', 8),\n",
       " ('title', 8),\n",
       " ('plus', 8),\n",
       " ('drinking', 8),\n",
       " ('mr', 8),\n",
       " ('brand', 8),\n",
       " ('luxurious', 8),\n",
       " ('crisis', 8),\n",
       " ('beat', 8),\n",
       " ('legend', 8),\n",
       " ('dangerous', 8),\n",
       " ('sleep', 8),\n",
       " ('second', 8),\n",
       " ('pizza', 8),\n",
       " ('feast', 8),\n",
       " ('beats', 8),\n",
       " ('kitchen', 8),\n",
       " ('private', 8),\n",
       " ('needs', 8),\n",
       " ('fire', 8),\n",
       " ('james', 8),\n",
       " ('cheese', 8),\n",
       " ('losing', 8),\n",
       " ('alzheimer', 8),\n",
       " ('hour', 8),\n",
       " ('career', 8),\n",
       " ('victoria', 8),\n",
       " ('tell', 8),\n",
       " ('uses', 8),\n",
       " ('featuring', 8),\n",
       " ('lived', 8),\n",
       " ('tips', 8),\n",
       " ('waste', 8),\n",
       " ('monster', 8),\n",
       " ('training', 8),\n",
       " ('animal', 8),\n",
       " ('send', 8),\n",
       " ('goal', 8),\n",
       " ('president', 8),\n",
       " ('beaches', 8),\n",
       " ('youre', 8),\n",
       " ('flight', 8),\n",
       " ('sauce', 8),\n",
       " ('dress', 8),\n",
       " ('hidden', 8),\n",
       " ('trial', 8),\n",
       " ('start', 8),\n",
       " ('cold', 8),\n",
       " ('promises', 8),\n",
       " ('government', 8),\n",
       " ('leicester', 8),\n",
       " ('playing', 8),\n",
       " ('bar', 8),\n",
       " ('kids', 8),\n",
       " ('building', 7),\n",
       " ('cash', 7),\n",
       " ('spent', 7),\n",
       " ('sees', 7),\n",
       " ('mobile', 7),\n",
       " ('centre', 7),\n",
       " ('shopping', 7),\n",
       " ('tells', 7),\n",
       " ('benefits', 7),\n",
       " ('secrets', 7),\n",
       " ('romantic', 7),\n",
       " ('seconds', 7),\n",
       " ('challenge', 7),\n",
       " ('strong', 7),\n",
       " ('wanted', 7),\n",
       " ('role', 7),\n",
       " ('apart', 7),\n",
       " ('bacteria', 7),\n",
       " ('teenagers', 7),\n",
       " ('newest', 7),\n",
       " ('medical', 7),\n",
       " ('major', 7),\n",
       " ('pictures', 7),\n",
       " ('wear', 7),\n",
       " ('sold', 7),\n",
       " ('host', 7),\n",
       " ('isis', 7),\n",
       " ('strike', 7),\n",
       " ('resort', 7),\n",
       " ('unique', 7),\n",
       " ('12', 7),\n",
       " ('captured', 7),\n",
       " ('army', 7),\n",
       " ('sydney', 7),\n",
       " ('entirely', 7),\n",
       " ('scenery', 7),\n",
       " ('travellers', 7),\n",
       " ('games', 7),\n",
       " ('past', 7),\n",
       " ('surface', 7),\n",
       " ('trying', 7),\n",
       " ('drinks', 7),\n",
       " ('michael', 7),\n",
       " ('late', 7),\n",
       " ('next', 7),\n",
       " ('rival', 7),\n",
       " ('coming', 7),\n",
       " ('drive', 7),\n",
       " ('last', 7),\n",
       " ('bird', 7),\n",
       " ('derby', 7),\n",
       " ('control', 7),\n",
       " ('also', 7),\n",
       " ('streets', 7),\n",
       " ('transfer', 7),\n",
       " ('miss', 7),\n",
       " ('class', 7),\n",
       " ('ultimate', 7),\n",
       " ('ring', 7),\n",
       " ('someone', 7),\n",
       " ('road', 7),\n",
       " ('yet', 7),\n",
       " ('straight', 7),\n",
       " ('order', 7),\n",
       " ('australia', 7),\n",
       " ('racist', 7),\n",
       " ('costs', 7),\n",
       " ('plastic', 7),\n",
       " ('lack', 7),\n",
       " ('syria', 7),\n",
       " ('ten', 7),\n",
       " ('suffers', 7),\n",
       " ('public', 7),\n",
       " ('driving', 7),\n",
       " ('problem', 7),\n",
       " ('glamorous', 7),\n",
       " ('went', 7),\n",
       " ('salad', 7),\n",
       " ('captures', 7),\n",
       " ('hope', 7),\n",
       " ('tried', 7),\n",
       " ('celebrates', 7),\n",
       " ('offer', 7),\n",
       " ('tumour', 7),\n",
       " ('simple', 7),\n",
       " ('western', 7),\n",
       " ('traditional', 7),\n",
       " ('2', 7),\n",
       " ('st', 7),\n",
       " ('turning', 7),\n",
       " ('success', 7),\n",
       " ('company', 7),\n",
       " ('country', 7),\n",
       " ('championship', 7),\n",
       " ('faces', 7),\n",
       " ('mcdonald', 7),\n",
       " ('story', 7),\n",
       " ('teen', 7),\n",
       " ('quirky', 7),\n",
       " ('created', 7),\n",
       " ('national', 7),\n",
       " ('rock', 7),\n",
       " ('roll', 7),\n",
       " ('cafe', 7),\n",
       " ('a-list', 7),\n",
       " ('avoid', 7),\n",
       " ('case', 7),\n",
       " ('raises', 7),\n",
       " ('damaged', 7),\n",
       " ('seven', 7),\n",
       " ('bridge', 7),\n",
       " ('pie', 7),\n",
       " ('rate', 7),\n",
       " ('fan', 7),\n",
       " ('leading', 7),\n",
       " ('town', 7),\n",
       " ('abuse', 7),\n",
       " ('sets', 7),\n",
       " ('foot', 7),\n",
       " ('green', 7),\n",
       " ('1', 7),\n",
       " ('fall', 7),\n",
       " ('wales', 7),\n",
       " ('ball', 7),\n",
       " ('died', 7),\n",
       " ('arent', 7),\n",
       " ('pain', 7),\n",
       " ('named', 7),\n",
       " ('dies', 7),\n",
       " ('sell', 7),\n",
       " ('box', 7),\n",
       " ('russian', 7),\n",
       " ('virtual', 7),\n",
       " ('everything', 7),\n",
       " ('true', 7),\n",
       " ('japan', 7),\n",
       " ('linked', 7),\n",
       " ('university', 7),\n",
       " ('champion', 7),\n",
       " ('dressed', 7),\n",
       " ('stylish', 7),\n",
       " ('diabetes', 7),\n",
       " ('nine', 7),\n",
       " ('chief', 7),\n",
       " ('accused', 7),\n",
       " ('florida', 7),\n",
       " ('different', 7),\n",
       " ('charged', 6),\n",
       " ('missing', 6),\n",
       " ('unable', 6),\n",
       " ('instead', 6),\n",
       " ('hanging', 6),\n",
       " ('mrs', 6),\n",
       " ('barcelona', 6),\n",
       " ('singer', 6),\n",
       " ('confirms', 6),\n",
       " ('fitness', 6),\n",
       " ('midfielder', 6),\n",
       " ('clubs', 6),\n",
       " ('track', 6),\n",
       " ('check', 6),\n",
       " ('married', 6),\n",
       " ('sells', 6),\n",
       " ('along', 6),\n",
       " ('rooms', 6),\n",
       " ('hotels', 6),\n",
       " ('desert', 6),\n",
       " ('leaving', 6),\n",
       " ('deadly', 6),\n",
       " ('worth', 6),\n",
       " ('poisoning', 6),\n",
       " ('bride', 6),\n",
       " ('countryside', 6),\n",
       " ('25', 6),\n",
       " ('near', 6),\n",
       " ('van', 6),\n",
       " ('popular', 6),\n",
       " ('nude', 6),\n",
       " ('staff', 6),\n",
       " ('cause', 6),\n",
       " ('calling', 6),\n",
       " ('china', 6),\n",
       " ('pair', 6),\n",
       " ('cooking', 6),\n",
       " ('samsung', 6),\n",
       " ('room', 6),\n",
       " ('enjoy', 6),\n",
       " ('splendid', 6),\n",
       " ('drop', 6),\n",
       " ('smile', 6),\n",
       " ('teenage', 6),\n",
       " ('friend', 6),\n",
       " ('lancaster', 6),\n",
       " ('tie', 6),\n",
       " ('make-up', 6),\n",
       " ('fly', 6),\n",
       " ('remote', 6),\n",
       " ('cheap', 6),\n",
       " ('surprise', 6),\n",
       " ('hollywood', 6),\n",
       " ('sports', 6),\n",
       " ('bath', 6),\n",
       " ('keeps', 6),\n",
       " ('crown', 6),\n",
       " ('supermarket', 6),\n",
       " ('robots', 6),\n",
       " ('awards', 6),\n",
       " ('checking', 6),\n",
       " ('research', 6),\n",
       " ('fear', 6),\n",
       " ('brilliant', 6),\n",
       " ('chilli', 6),\n",
       " ('chicken', 6),\n",
       " ('lights', 6),\n",
       " ('photographer', 6),\n",
       " ('manager', 6),\n",
       " ('paul', 6),\n",
       " ('convicted', 6),\n",
       " ('evans', 6),\n",
       " ('toddler', 6),\n",
       " ('dogs', 6),\n",
       " ('prices', 6),\n",
       " ('defender', 6),\n",
       " ('debut', 6),\n",
       " ('parties', 6),\n",
       " ('fa', 6),\n",
       " ('thin', 6),\n",
       " ('male', 6),\n",
       " ('mind', 6),\n",
       " ('heads', 6),\n",
       " ('jet', 6),\n",
       " ('expect', 6),\n",
       " ('weather', 6),\n",
       " ('charles', 6),\n",
       " ('amid', 6),\n",
       " ('selfies', 6),\n",
       " ('ruins', 6),\n",
       " ('ft', 6),\n",
       " ('sound', 6),\n",
       " ('defeat', 6),\n",
       " ('less', 6),\n",
       " ('japanese', 6),\n",
       " ('digital', 6),\n",
       " ('youll', 6),\n",
       " ('trip', 6),\n",
       " ('cambridge', 6),\n",
       " ('bed', 6),\n",
       " ('extraordinary', 6),\n",
       " ('fears', 6),\n",
       " ('lot', 6),\n",
       " ('driver', 6),\n",
       " ('surprising', 6),\n",
       " ('computer', 6),\n",
       " ('dark', 6),\n",
       " ('universe', 6),\n",
       " ('dementia', 6),\n",
       " ('adventure', 6),\n",
       " ('holidaymakers', 6),\n",
       " ('boat', 6),\n",
       " ('flights', 6),\n",
       " ('rangers', 6),\n",
       " ('goalkeeper', 6),\n",
       " ('add', 6),\n",
       " ('coffee', 6),\n",
       " ('person', 6),\n",
       " ('sight', 6),\n",
       " ('lbs', 6),\n",
       " ('failed', 6),\n",
       " ('selling', 6),\n",
       " ('god', 6),\n",
       " ('clothing', 6),\n",
       " ('300', 6),\n",
       " ('juventus', 6),\n",
       " ('bond', 6),\n",
       " ('dazzling', 6),\n",
       " ('students', 6),\n",
       " ('theyre', 6),\n",
       " ('dancing', 6),\n",
       " ('held', 6),\n",
       " ('fell', 6),\n",
       " ('mark', 6),\n",
       " ('cool', 6),\n",
       " ('limbs', 6),\n",
       " ('8', 6),\n",
       " ('14', 6),\n",
       " ('loss', 6),\n",
       " ('taste', 6),\n",
       " ('caviar', 6),\n",
       " ('crazy', 6),\n",
       " ('mass', 6),\n",
       " ('kidney', 6),\n",
       " ('rising', 6),\n",
       " ('beckham', 6),\n",
       " ('mansion', 6),\n",
       " ('cups', 6),\n",
       " ('vaccine', 6),\n",
       " ('naked', 6),\n",
       " ('ride', 6),\n",
       " ('changed', 6),\n",
       " ('becoming', 6),\n",
       " ('lovers', 6),\n",
       " ('crystal', 6),\n",
       " ('english', 6),\n",
       " ('performance', 6),\n",
       " ('movie', 6),\n",
       " ('step', 6),\n",
       " ('low', 6),\n",
       " ('damage', 6),\n",
       " ('bacon', 6),\n",
       " ('investigation', 6),\n",
       " ('safe', 6),\n",
       " ('cocktails', 6),\n",
       " ('prove', 6),\n",
       " ('launch', 6),\n",
       " ('jobs', 6),\n",
       " ('machine', 6),\n",
       " ('always', 6),\n",
       " ('aid', 6),\n",
       " ('controversial', 6),\n",
       " ('sweet', 6),\n",
       " ('ocean', 6),\n",
       " ('clothes', 6),\n",
       " ('site', 6),\n",
       " ('direction', 6),\n",
       " ('solar', 6),\n",
       " ('pub', 6),\n",
       " ('moves', 6),\n",
       " ('means', 6),\n",
       " ('carpet', 6),\n",
       " ('together', 6),\n",
       " ('landing', 6),\n",
       " ('trend', 6),\n",
       " ('stuffed', 6),\n",
       " ...]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2267"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train.Label.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2040"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9505 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 9000\n",
    "MAX_SEQUENCE_LENGTH = 30\n",
    "\n",
    "#texts = train.Headline.append(test.Headline).reindex()\n",
    "texts = df.no_stopwords\n",
    "\n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "tokenizer = Tokenizer() #num_words=MAX_NB_WORDS\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (2267, 30)\n",
      "Shape of label tensor: (2040, 1)\n"
     ]
    }
   ],
   "source": [
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "\n",
    "test_data = data[train_index:]\n",
    "data = data[:train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dict = defaultdict(int)\n",
    "for number,item in enumerate(df.Category.unique()):\n",
    "    category_dict[item] = number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Category_number'] = df['Category'].apply(lambda x : category_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_category = df.Category_number[indices][:-nb_validation_samples]\n",
    "x_val_category = df.Category_number[indices][-nb_validation_samples:]\n",
    "x_test_category = df.Category_number[train_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312     0\n",
       "884     1\n",
       "1269    8\n",
       "2033    8\n",
       "1263    7\n",
       "       ..\n",
       "1823    0\n",
       "1582    8\n",
       "1722    0\n",
       "1906    6\n",
       "731     2\n",
       "Name: Category_number, Length: 1836, dtype: int64"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.Category.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### countinue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 25\n",
    "x_train_category = tf.one_hot(x_train_category, depth=depth)\n",
    "x_val_category = tf.one_hot(x_val_category, depth=depth)\n",
    "x_test_category = tf.one_hot(x_test_category, depth=depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "y_val = tf.convert_to_tensor(y_val, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(204, 1), dtype=float32, numpy=\n",
       "array([[2.6666667],\n",
       "       [4.5      ],\n",
       "       [3.3333333],\n",
       "       [2.3333333],\n",
       "       [3.3333333],\n",
       "       [4.5      ],\n",
       "       [2.5      ],\n",
       "       [3.3333333],\n",
       "       [3.       ],\n",
       "       [3.       ],\n",
       "       [4.       ],\n",
       "       [3.3333333],\n",
       "       [2.       ],\n",
       "       [3.       ],\n",
       "       [2.6666667],\n",
       "       [2.6666667],\n",
       "       [2.3333333],\n",
       "       [2.6666667],\n",
       "       [3.6666667],\n",
       "       [1.5      ],\n",
       "       [4.       ],\n",
       "       [3.       ],\n",
       "       [3.6666667],\n",
       "       [2.6666667],\n",
       "       [3.       ],\n",
       "       [3.3333333],\n",
       "       [3.3333333],\n",
       "       [4.       ],\n",
       "       [2.6666667],\n",
       "       [2.       ],\n",
       "       [3.       ],\n",
       "       [2.       ],\n",
       "       [2.3333333],\n",
       "       [2.6666667],\n",
       "       [4.6666665],\n",
       "       [3.6666667],\n",
       "       [2.3333333],\n",
       "       [3.       ],\n",
       "       [2.5      ],\n",
       "       [2.6666667],\n",
       "       [3.3333333],\n",
       "       [2.3333333],\n",
       "       [5.       ],\n",
       "       [2.3333333],\n",
       "       [3.       ],\n",
       "       [3.3333333],\n",
       "       [3.3333333],\n",
       "       [4.3333335],\n",
       "       [3.       ],\n",
       "       [3.3333333],\n",
       "       [3.3333333],\n",
       "       [3.       ],\n",
       "       [2.3333333],\n",
       "       [4.5      ],\n",
       "       [2.6666667],\n",
       "       [2.3333333],\n",
       "       [3.6666667],\n",
       "       [3.6666667],\n",
       "       [2.       ],\n",
       "       [3.       ],\n",
       "       [4.       ],\n",
       "       [3.       ],\n",
       "       [3.6666667],\n",
       "       [3.6666667],\n",
       "       [3.       ],\n",
       "       [2.3333333],\n",
       "       [3.6666667],\n",
       "       [3.       ],\n",
       "       [2.       ],\n",
       "       [3.6666667],\n",
       "       [4.3333335],\n",
       "       [2.       ],\n",
       "       [3.       ],\n",
       "       [3.6666667],\n",
       "       [4.3333335],\n",
       "       [2.6666667],\n",
       "       [4.       ],\n",
       "       [4.       ],\n",
       "       [3.5      ],\n",
       "       [2.       ],\n",
       "       [3.3333333],\n",
       "       [3.       ],\n",
       "       [3.       ],\n",
       "       [3.6666667],\n",
       "       [4.       ],\n",
       "       [4.3333335],\n",
       "       [2.3333333],\n",
       "       [3.       ],\n",
       "       [4.3333335],\n",
       "       [2.3333333],\n",
       "       [4.5      ],\n",
       "       [4.       ],\n",
       "       [3.       ],\n",
       "       [4.       ],\n",
       "       [3.6666667],\n",
       "       [3.       ],\n",
       "       [3.3333333],\n",
       "       [3.6666667],\n",
       "       [3.       ],\n",
       "       [2.6666667],\n",
       "       [2.5      ],\n",
       "       [3.       ],\n",
       "       [2.6666667],\n",
       "       [3.5      ],\n",
       "       [3.       ],\n",
       "       [3.       ],\n",
       "       [3.6666667],\n",
       "       [2.3333333],\n",
       "       [3.3333333],\n",
       "       [2.3333333],\n",
       "       [4.       ],\n",
       "       [3.       ],\n",
       "       [4.       ],\n",
       "       [1.3333334],\n",
       "       [3.6666667],\n",
       "       [2.       ],\n",
       "       [2.6666667],\n",
       "       [3.6666667],\n",
       "       [2.       ],\n",
       "       [3.6666667],\n",
       "       [3.3333333],\n",
       "       [4.       ],\n",
       "       [2.6666667],\n",
       "       [3.       ],\n",
       "       [3.6666667],\n",
       "       [3.3333333],\n",
       "       [4.       ],\n",
       "       [4.3333335],\n",
       "       [3.       ],\n",
       "       [4.       ],\n",
       "       [4.       ],\n",
       "       [4.3333335],\n",
       "       [4.3333335],\n",
       "       [2.3333333],\n",
       "       [4.3333335],\n",
       "       [4.       ],\n",
       "       [2.3333333],\n",
       "       [3.       ],\n",
       "       [4.       ],\n",
       "       [5.       ],\n",
       "       [1.6666666],\n",
       "       [2.3333333],\n",
       "       [2.3333333],\n",
       "       [3.       ],\n",
       "       [2.6666667],\n",
       "       [3.6666667],\n",
       "       [2.3333333],\n",
       "       [4.5      ],\n",
       "       [2.6666667],\n",
       "       [3.       ],\n",
       "       [4.       ],\n",
       "       [4.3333335],\n",
       "       [3.3333333],\n",
       "       [3.3333333],\n",
       "       [3.3333333],\n",
       "       [2.       ],\n",
       "       [2.3333333],\n",
       "       [4.3333335],\n",
       "       [2.5      ],\n",
       "       [3.3333333],\n",
       "       [3.       ],\n",
       "       [3.6666667],\n",
       "       [3.3333333],\n",
       "       [3.3333333],\n",
       "       [2.3333333],\n",
       "       [2.6666667],\n",
       "       [2.       ],\n",
       "       [3.       ],\n",
       "       [2.6666667],\n",
       "       [3.       ],\n",
       "       [3.3333333],\n",
       "       [3.       ],\n",
       "       [3.       ],\n",
       "       [2.6666667],\n",
       "       [2.3333333],\n",
       "       [3.       ],\n",
       "       [2.6666667],\n",
       "       [3.6666667],\n",
       "       [2.6666667],\n",
       "       [3.       ],\n",
       "       [3.6666667],\n",
       "       [3.       ],\n",
       "       [2.6666667],\n",
       "       [2.6666667],\n",
       "       [4.6666665],\n",
       "       [2.6666667],\n",
       "       [2.6666667],\n",
       "       [3.       ],\n",
       "       [2.3333333],\n",
       "       [2.3333333],\n",
       "       [3.6666667],\n",
       "       [2.       ],\n",
       "       [3.3333333],\n",
       "       [3.       ],\n",
       "       [3.6666667],\n",
       "       [3.3333333],\n",
       "       [2.6666667],\n",
       "       [3.6666667],\n",
       "       [3.6666667],\n",
       "       [1.6666666],\n",
       "       [3.       ],\n",
       "       [2.       ],\n",
       "       [3.       ],\n",
       "       [3.6666667]], dtype=float32)>"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2196016 word vectors.\n"
     ]
    }
   ],
   "source": [
    "GLOVE_DIR = os.getcwd()\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.840B.300d.txt'))\n",
    "for line in f:\n",
    "    values = line.split(' ')\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moneymillion\n",
      "瞿\n",
      "sensatori\n",
      "colborn\n",
      "wetherspoon\n",
      "straubenzee\n",
      "kassig\n",
      "bloggling\n",
      "casilli\n",
      "washoku\n",
      "kalette\n",
      "ratajkowski\n",
      "mcconnel\n",
      "schapelle\n",
      "manorexia\n",
      "zmapp\n",
      "ntas\n",
      "williamsfield\n",
      "tressful\n",
      "marcu\n",
      "radamel\n",
      "hitchbot\n",
      "143840\n",
      "blueberrie\n",
      "satorova\n",
      "parahawking\n",
      "lasource\n",
      "gignac\n",
      "vvb\n",
      "taylforth\n",
      "lannisters\n",
      "versini\n",
      "263000\n",
      "leonore\n",
      "kintbury\n",
      "278000\n",
      "latelier\n",
      "shooters4\n",
      "flumps\n",
      "sraphine\n",
      "solanke\n",
      "silbury\n",
      "marmadukes\n",
      "92million\n",
      "ossetra\n",
      "sølveig\n",
      "urfboard\n",
      "clooneys\n",
      "huguette\n",
      "pogba\n",
      "crabzilla\n",
      "kuratas\n",
      "orionid\n",
      "pedraza\n",
      "seewald\n",
      "lovren\n",
      "jambos\n",
      "duffen\n",
      "gunton\n",
      "udons\n",
      "headguards\n",
      "leiby\n",
      "kletzky\n",
      "aisleyne\n",
      "bregancon\n",
      "103f\n",
      "hudl\n",
      "endage\n",
      "mowatt\n",
      "megaburgerpizza\n",
      "mucklow\n",
      "exually\n",
      "hockingly\n",
      "hinxton\n",
      "colchicums\n",
      "bildeston\n",
      "megeve\n",
      "alamuddin\n",
      "robach\n",
      "downtons\n",
      "huashan\n",
      "ledoyen\n",
      "graubunden\n",
      "wagguccinos\n",
      "revoluntionise\n",
      "swaffham\n",
      "gavroche\n",
      "calded\n",
      "ötzi\n",
      "agdal\n",
      "battersby\n",
      "ramesses\n",
      "mh370\n",
      "tarfish\n",
      "twivial\n",
      "bellecote\n",
      "bennewith\n",
      "jezki\n",
      "argentinosaurus\n",
      "marouane\n",
      "hadza\n",
      "eyeteq\n",
      "honut\n",
      "antikythera\n",
      "mcvitie\n",
      "madagascan\n",
      "yarnold\n",
      "yobaba\n",
      "lyth\n",
      "healthkit\n",
      "ershver\n",
      "tooni\n",
      "monhrr\n",
      "uperlanguage\n",
      "lopilato\n",
      "ad70\n",
      "sweetroot\n",
      "a46\n",
      "sportsmail\n",
      "bafetimbi\n",
      "gomis\n",
      "willerton\n",
      "priceles\n",
      "humphrys\n",
      "baynes\n",
      "instagrammers\n",
      "uperpower\n",
      "touessrok\n",
      "guman\n",
      "monis\n",
      "chemmy\n",
      "ampika\n",
      "pickston\n",
      "backgrounto\n",
      "thoren\n",
      "litvinenko\n",
      "minoans\n",
      "dymphna\n",
      "enner\n",
      "moët\n",
      "twinstagram\n",
      "froome\n",
      "hyperloop\n",
      "mccoist\n",
      "evertomb\n",
      "weligton\n",
      "uicidal\n",
      "mh17\n",
      "gredos\n",
      "woolton\n",
      "gwynnie\n",
      "searcys\n",
      "mimas\n",
      "ickening\n",
      "foodstagrammer\n",
      "urprise\n",
      "missionarie\n",
      "brelfie\n",
      "plebgate\n",
      "ubversive\n",
      "mertesacker\n",
      "fifpro\n",
      "mbye\n",
      "bishoo\n",
      "ardche\n",
      "derryn\n",
      "flakka\n",
      "altamura\n",
      "skuse\n",
      "chubbuck\n",
      "railton\n",
      "cdbury\n",
      "mcerlane\n",
      "u21s\n",
      "proudlock\n",
      "scudamore\n",
      "aqap\n",
      "gnter\n",
      "leeuwenhoek\n",
      "gizzi\n",
      "maksims\n",
      "uvarenko\n",
      "salzberg\n",
      "crapser\n",
      "martinhal\n",
      "mckendrick\n",
      "whitear\n",
      "isogawa\n",
      "yazidi\n",
      "eurocamp\n",
      "argeles\n",
      "idebar\n",
      "verasamy\n"
     ]
    }
   ],
   "source": [
    "#Glove\n",
    "EMBEDDING_DIM = embeddings_index['car'].shape[0]\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word,i in word_index.items():\n",
    "    #if i < num_words:\n",
    "        #print(word)\n",
    "        emb_vec=embeddings_index.get(word)\n",
    "        if emb_vec is not None:\n",
    "            embedding_matrix[i]=emb_vec\n",
    "            #print(i)\n",
    "        else: print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding_matrix = np.load('embedding_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(min_delta = 0.001, mode = 'max', monitor='val_custom_accuracy_function', patience = 3)\n",
    "callback = [early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Self_Attention(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(Self_Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # 為該層建立一個可訓練的權重\n",
    "        #inputs.shape = (batch_size, time_steps, seq_len)\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(3,input_shape[2], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "\n",
    "        super(Self_Attention, self).build(input_shape)  # 一定要在最後呼叫它\n",
    "\n",
    "    def call(self, x):\n",
    "        WQ = K.dot(x, self.kernel[0])\n",
    "        WK = K.dot(x, self.kernel[1])\n",
    "        WV = K.dot(x, self.kernel[2])\n",
    "\n",
    "        print(\"WQ.shape\",WQ.shape)\n",
    "\n",
    "        print(\"K.permute_dimensions(WK, [0, 2, 1]).shape\",K.permute_dimensions(WK, [0, 2, 1]).shape)\n",
    "\n",
    "\n",
    "        QK = K.batch_dot(WQ,K.permute_dimensions(WK, [0, 2, 1]))\n",
    "\n",
    "        QK = QK / (64**0.5)\n",
    "\n",
    "        QK = K.softmax(QK)\n",
    "\n",
    "        print(\"QK.shape\",QK.shape)\n",
    "\n",
    "        V = K.batch_dot(QK,WV)\n",
    "\n",
    "        return V\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "\n",
    "        return (input_shape[0],input_shape[1],self.output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_function(y_true, y_pred):\n",
    "    #weight = np.array([1,2,3,4,5],dtype='f').reshape(-1,1)\n",
    "    #weight = tf.convert_to_tensor(weight)\n",
    "    #weight = tf.Variable(np.array([1,2,3,4,5],dtype='f').reshape(-1,1), dtype=tf.float32)\n",
    "    #squared_difference = tf.square(y_true - tf.matmul(y_pred,weight)) #+tf.square(5 - tf.matmul(y_pred,weight))+tf.square(1 - tf.matmul(y_pred,weight))\n",
    "    #print(tf.square(3.15 - tf.matmul(y_pred,weight))[0])\n",
    "    squared_difference = tf.square(y_true - y_pred)+0.1*tf.square(1 - y_pred)+0.1*tf.square(5 - y_pred)\n",
    "    return tf.reduce_mean(squared_difference, axis=-1)\n",
    "\n",
    "\n",
    "def custom_accuracy_function(y_true, y_pred):\n",
    "    #if tf.math.argmax(y_true,1)-tf.math.argmax(y_pred,1)==0:\n",
    "        #a = 1 \n",
    "    a=abs(y_true-y_pred)<0.5\n",
    "    return K.mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words=len(word_index)+1\n",
    "\n",
    "embedding = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_self_attention import SeqSelfAttention,SeqWeightedAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding)\n",
    "model.add(SeqSelfAttention(attention_activation='softmax'))\n",
    "model.add(Bidirectional(LSTM(units=128, dropout=0.2,recurrent_dropout=0.2)))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))\n",
    "optimzer=Adam(learning_rate=1e-4)\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=optimzer,\n",
    "              metrics=[custom_accuracy_function])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WQ.shape (None, 30, 256)\n",
      "K.permute_dimensions(WK, [0, 2, 1]).shape (None, 256, 30)\n",
      "QK.shape (None, 30, 30)\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "category_input = Input(shape=(depth,), dtype='float32')\n",
    "embedded_sequences = embedding(sequence_input)\n",
    "embed_self = Self_Attention(256)(embedded_sequences)\n",
    "#embed_self = Self_Attention(64)(embed_self)\n",
    "#a1 = Conv1D(32, 3, activation='relu')(embed_self)\n",
    "#a2 = Conv1D(32, 3, activation='relu')(embedded_sequences)\n",
    "#a = concatenate([a1, a2], axis=1)\n",
    "#a = MaxPooling1D(2)(a1)\n",
    "#b1 = Conv1D(32, 4, activation='relu')(embed_self)\n",
    "#b2 = Conv1D(32, 4, activation='relu')(embedded_sequences)\n",
    "#b = concatenate([b1, b2], axis=1)\n",
    "#b = MaxPooling1D(2)(b1) # global max pooling\n",
    "#c = Conv1D(32, 5, activation='relu')(embedded_sequences)\n",
    "#c = MaxPooling1D(2)(c)\n",
    "#x = concatenate([a, b], axis=1)\n",
    "\n",
    "x = Bidirectional(LSTM(128, dropout=0.1,recurrent_dropout=0.1,return_sequences=True))(embed_self)\n",
    "#x = LSTM(128, dropout=0.2,recurrent_dropout=0.2,return_sequences=True)(embed_self)\n",
    "#x = BatchNormalization()(x)\n",
    "x = (LSTM(64, dropout=0.2,recurrent_dropout=0.2))(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = concatenate([x,category_input])\n",
    "#x = Flatten()(x)\n",
    "#x = Dense(100,kernel_initializer='random_uniform', activation='relu')(x)\n",
    "x = Dense(32,kernel_initializer='random_uniform', activation='relu')(x)\n",
    "#return_sequences=True\n",
    "preds = Dense(1)(x)\n",
    "\n",
    "optimzer=Adam(learning_rate=1e-4)\n",
    "\n",
    "model = Model([sequence_input,category_input], preds)\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=optimzer,\n",
    "              metrics=[custom_accuracy_function])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_59\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_63 (InputLayer)           [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 30, 300)      2851800     input_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "self__attention_32 (Self_Attent (None, 30, 256)      230400      embedding_4[15][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_18 (Bidirectional (None, 30, 256)      394240      self__attention_32[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lstm_54 (LSTM)                  (None, 64)           82176       bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 64)           0           lstm_54[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_64 (InputLayer)           [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 89)           0           dropout_16[0][0]                 \n",
      "                                                                 input_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 32)           2880        concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 1)            33          dense_60[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,561,529\n",
      "Trainable params: 709,729\n",
      "Non-trainable params: 2,851,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WQ.shape (None, 30, 256)\n",
      "K.permute_dimensions(WK, [0, 2, 1]).shape (None, 256, 30)\n",
      "QK.shape (None, 30, 30)\n",
      "WQ.shape (None, 30, 256)\n",
      "K.permute_dimensions(WK, [0, 2, 1]).shape (None, 256, 30)\n",
      "QK.shape (None, 30, 30)\n",
      "58/58 [==============================] - ETA: 0s - loss: 7.5451 - custom_accuracy_function: 0.0102WQ.shape (None, 30, 256)\n",
      "K.permute_dimensions(WK, [0, 2, 1]).shape (None, 256, 30)\n",
      "QK.shape (None, 30, 30)\n",
      "58/58 [==============================] - 8s 135ms/step - loss: 7.5451 - custom_accuracy_function: 0.0102 - val_loss: 2.4193 - val_custom_accuracy_function: 0.1042\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 7s 124ms/step - loss: 0.9287 - custom_accuracy_function: 0.3869 - val_loss: 0.5366 - val_custom_accuracy_function: 0.4955\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 7s 123ms/step - loss: 0.5427 - custom_accuracy_function: 0.4797 - val_loss: 0.5275 - val_custom_accuracy_function: 0.4970\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 7s 123ms/step - loss: 0.5233 - custom_accuracy_function: 0.4799 - val_loss: 0.5216 - val_custom_accuracy_function: 0.5015\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 7s 124ms/step - loss: 0.5103 - custom_accuracy_function: 0.4943 - val_loss: 0.5157 - val_custom_accuracy_function: 0.5193\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 7s 124ms/step - loss: 0.4905 - custom_accuracy_function: 0.5043 - val_loss: 0.5139 - val_custom_accuracy_function: 0.5193\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 7s 124ms/step - loss: 0.4762 - custom_accuracy_function: 0.5226 - val_loss: 0.5169 - val_custom_accuracy_function: 0.5149\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 7s 124ms/step - loss: 0.4670 - custom_accuracy_function: 0.5239 - val_loss: 0.5118 - val_custom_accuracy_function: 0.5327\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 7s 124ms/step - loss: 0.4618 - custom_accuracy_function: 0.5325 - val_loss: 0.5032 - val_custom_accuracy_function: 0.5461\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - 7s 123ms/step - loss: 0.4407 - custom_accuracy_function: 0.5372 - val_loss: 0.5042 - val_custom_accuracy_function: 0.5283\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - 7s 124ms/step - loss: 0.4487 - custom_accuracy_function: 0.5375 - val_loss: 0.4948 - val_custom_accuracy_function: 0.5461\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - 7s 124ms/step - loss: 0.4348 - custom_accuracy_function: 0.5544 - val_loss: 0.4951 - val_custom_accuracy_function: 0.5506\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - 7s 123ms/step - loss: 0.4209 - custom_accuracy_function: 0.5578 - val_loss: 0.4888 - val_custom_accuracy_function: 0.5551\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - 7s 123ms/step - loss: 0.4117 - custom_accuracy_function: 0.5487 - val_loss: 0.4865 - val_custom_accuracy_function: 0.5551\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - 7s 124ms/step - loss: 0.4026 - custom_accuracy_function: 0.5550 - val_loss: 0.4848 - val_custom_accuracy_function: 0.5506\n",
      "Epoch 16/100\n",
      "58/58 [==============================] - 7s 123ms/step - loss: 0.4062 - custom_accuracy_function: 0.5550 - val_loss: 0.4917 - val_custom_accuracy_function: 0.5461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fce9d7b10d0>"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x_train, x_train_category], y_train, validation_data=([x_val, x_val_category], y_val),\n",
    "          epochs=100, batch_size=32, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WQ.shape (None, 30, 256)\n",
      "K.permute_dimensions(WK, [0, 2, 1]).shape (None, 256, 30)\n",
      "QK.shape (None, 30, 30)\n"
     ]
    }
   ],
   "source": [
    "y_val_pre = model.predict([x_val,x_val_category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.49172208], dtype=float32)>"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((y_val - y_val_pre)**2 )/ len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<0.1% Accuracy = [0.10784314]\n",
      "<0.2% Accuracy = [0.21568628]\n",
      "<0.3% Accuracy = [0.34313726]\n",
      "<0.4% Accuracy = [0.45588234]\n",
      "<0.5% Accuracy = [0.53431374]\n"
     ]
    }
   ],
   "source": [
    "threshold_list = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "    \n",
    "for threshold in threshold_list:\n",
    "    \n",
    "    accuracy = sum(tf.cast((abs(y_val - y_val_pre)<threshold), tf.float32)) / len(y_val)\n",
    "    print('<{}% Accuracy = {}'.format(threshold, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub=pd.read_csv('sampleSubmission.csv')\n",
    "sample_sub = sample_sub.sort_values(by=['ID'])\n",
    "y_pre=model.predict([test_data,x_test_category])\n",
    "sub=pd.DataFrame({'ID':sample_sub['ID'].values.tolist(),'Label':y_pre.reshape(-1,)})\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0655043 3.7192523\n"
     ]
    }
   ],
   "source": [
    "print(y_pre.min(),y_pre.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Layer Self_Attention has arguments in `__init__` and therefore must override `get_config`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-487-b120a36ffd3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_final.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m   1977\u001b[0m     \"\"\"\n\u001b[1;32m   1978\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 1979\u001b[0;31m                     signatures, options)\n\u001b[0m\u001b[1;32m   1980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m   def save_weights(self,\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    129\u001b[0m           'or using `save_weights`.')\n\u001b[1;32m    130\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[0;32m--> 131\u001b[0;31m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[1;32m    132\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mmodel_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_metadata\u001b[0;34m(model, include_optimizer, require_config)\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrequire_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m   metadata = dict(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_metadata\u001b[0;34m(model, include_optimizer, require_config)\u001b[0m\n\u001b[1;32m    152\u001b[0m   \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrequire_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_network_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mget_network_config\u001b[0;34m(network, serialize_layer_fn)\u001b[0m\n\u001b[1;32m   1276\u001b[0m         \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m     \u001b[0mlayer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserialize_layer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m     \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inbound_nodes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mserialize_keras_object\u001b[0;34m(instance)\u001b[0m\n\u001b[1;32m    248\u001b[0m         return serialize_keras_class_and_config(\n\u001b[1;32m    249\u001b[0m             name, {_LAYER_UNDEFINED_CONFIG_KEY: True})\n\u001b[0;32m--> 250\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0mserialization_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mserialize_keras_object\u001b[0;34m(instance)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_registered_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m       \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_SKIP_FAILED_SERIALIZATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m       raise NotImplementedError('Layer %s has arguments in `__init__` and '\n\u001b[1;32m    677\u001b[0m                                 \u001b[0;34m'therefore must override `get_config`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m                                 self.__class__.__name__)\n\u001b[0m\u001b[1;32m    679\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Layer Self_Attention has arguments in `__init__` and therefore must override `get_config`."
     ]
    }
   ],
   "source": [
    "model.save('model_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
